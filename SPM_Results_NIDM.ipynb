{
 "metadata": {
  "name": "SPM_Results_NIDM"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import prov.model as prov\n",
      "from uuid import uuid1\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SPM Results Metadata\n",
      "\n",
      "#temporarily store this data in local variables. This will be replaced by parsing SPM.mat, xCon.mat, etc...\n",
      "spm_metadata = {'hthresh_t':3.10, \n",
      "                'hthresh_p':0.001,\n",
      "                'ext_thresh_vx':0,\n",
      "                'ext_thresh_p':1.0,\n",
      "                'exp_vox_cluster':60.632,\n",
      "                'exp_num_clusters':9.51,\n",
      "                'dof':[1.0, 1027.0],\n",
      "                'fwhm_mm':[15.8, 15.8, 16.6],\n",
      "                'fwhm_voxels':[7.9, 7.9, 8.3],\n",
      "                'vol_vox':504268,\n",
      "                'vol_res':938.3,\n",
      "                'vox_size':[2.0, 2.0, 2.0]}\n",
      "\n",
      "\n",
      "\n",
      "#encoding results table as a dictionary of dictionaries\n",
      "#keys could be changed from the ones I'm using here to ones that use the terms from our terminology (possibly)\n",
      "spm_results_table={0: dict(set_level_p=0.836,set_level_c=7,cluster_level_FWEcorr_p=0.831,cluster_level_FDRcorr_q=0.655, cluster_level_Ke=99, \n",
      "                           cluster_level_Uncorr_p=0.187, peak_level_FWEcorr_p=0.728, peak_level_FDRcorr_p=0.464, peak_level_T=3.80, \n",
      "                           peak_level_Z=3.79, peak_level_Uncorr_p=0.000, loc=\"[48, 42,0]\"),\n",
      "                   1: dict(set_level_p=\"[]\",set_level_c=\"[]\",cluster_level_FWEcorr_p=\"\",cluster_level_FDRcorr_q=\"[]\", cluster_level_Ke=\"[]\", \n",
      "                           cluster_level_Uncorr_p=\"\",peak_level_FWEcorr_p=0.994, peak_level_FDRcorr_p=0.904, peak_level_T=3.34, \n",
      "                           peak_level_Z=3.33, peak_level_Uncorr_p=0.000, loc=\"[54, 36,-12]\"),\n",
      "                   2: dict(set_level_p=\"[]\",set_level_c=\"[]\",cluster_level_FWEcorr_p=0.145,cluster_level_FDRcorr_q=0.115, cluster_level_Ke=380, \n",
      "                           cluster_level_Uncorr_p=0.016, peak_level_FWEcorr_p=0.756, peak_level_FDRcorr_p=0.464, peak_level_T=3.78, \n",
      "                           peak_level_Z=3.76, peak_level_Uncorr_p=0.000, loc=\"[-20, 52,32]\"),\n",
      "                   3: dict(set_level_p=\"[]\",set_level_c=\"[]\",cluster_level_FWEcorr_p=\"[]\",cluster_level_FDRcorr_q=\"[]\", cluster_level_Ke=\"[]\", \n",
      "                           cluster_level_Uncorr_p=\"[]\",peak_level_FWEcorr_p=0.994, peak_level_FDRcorr_p=0.904, peak_level_T=3.34, \n",
      "                           peak_level_Z=3.33, peak_level_Uncorr_p=0.000, loc=\"[54, 36,-12]\"),\n",
      "                   4: dict(set_level_p=\"[]\",set_level_c=\"[]\",cluster_level_FWEcorr_p=0.998,cluster_level_FDRcorr_q=0.925, cluster_level_Ke=12, \n",
      "                           cluster_level_Uncorr_p=0.663, peak_level_FWEcorr_p=0.997, peak_level_FDRcorr_p=0.904, peak_level_T=3.30, \n",
      "                           peak_level_Z=3.29, peak_level_Uncorr_p=0.001, loc=\"[38, 52,-30]\")}\n",
      "                   \n",
      "    \n",
      "#sample query of spm_results_table for results with large t-score\n",
      "large_t=set(dat for dat in spm_results_table if spm_results_table[dat]['peak_level_T'] > 3.00)\n",
      "#print results from query\n",
      "print 'example query (t-stats > 3.0): set(dat for dat in spm_results_table if spm_results_table[dat][''peak_level_T''] > 3.00)\\n'\n",
      "for i in large_t:\n",
      "    print spm_results_table[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "example query (t-stats > 3.0): set(dat for dat in spm_results_table if spm_results_table[dat][peak_level_T] > 3.00)\n",
        "\n",
        "{'loc': '[48, 42,0]', 'cluster_level_FDRcorr_q': 0.655, 'cluster_level_Ke': 99, 'peak_level_Uncorr_p': 0.0, 'peak_level_FWEcorr_p': 0.728, 'peak_level_FDRcorr_p': 0.464, 'set_level_c': 7, 'peak_level_T': 3.8, 'cluster_level_Uncorr_p': 0.187, 'peak_level_Z': 3.79, 'cluster_level_FWEcorr_p': 0.831, 'set_level_p': 0.836}\n",
        "{'loc': '[54, 36,-12]', 'cluster_level_FDRcorr_q': '[]', 'cluster_level_Ke': '[]', 'peak_level_Uncorr_p': 0.0, 'peak_level_FWEcorr_p': 0.994, 'peak_level_FDRcorr_p': 0.904, 'set_level_c': '[]', 'peak_level_T': 3.34, 'cluster_level_Uncorr_p': '', 'peak_level_Z': 3.33, 'cluster_level_FWEcorr_p': '', 'set_level_p': '[]'}\n",
        "{'loc': '[-20, 52,32]', 'cluster_level_FDRcorr_q': 0.115, 'cluster_level_Ke': 380, 'peak_level_Uncorr_p': 0.0, 'peak_level_FWEcorr_p': 0.756, 'peak_level_FDRcorr_p': 0.464, 'set_level_c': '[]', 'peak_level_T': 3.78, 'cluster_level_Uncorr_p': 0.016, 'peak_level_Z': 3.76, 'cluster_level_FWEcorr_p': 0.145, 'set_level_p': '[]'}\n",
        "{'loc': '[54, 36,-12]', 'cluster_level_FDRcorr_q': '[]', 'cluster_level_Ke': '[]', 'peak_level_Uncorr_p': 0.0, 'peak_level_FWEcorr_p': 0.994, 'peak_level_FDRcorr_p': 0.904, 'set_level_c': '[]', 'peak_level_T': 3.34, 'cluster_level_Uncorr_p': '[]', 'peak_level_Z': 3.33, 'cluster_level_FWEcorr_p': '[]', 'set_level_p': '[]'}\n",
        "{'loc': '[38, 52,-30]', 'cluster_level_FDRcorr_q': 0.925, 'cluster_level_Ke': 12, 'peak_level_Uncorr_p': 0.001, 'peak_level_FWEcorr_p': 0.997, 'peak_level_FDRcorr_p': 0.904, 'set_level_c': '[]', 'peak_level_T': 3.3, 'cluster_level_Uncorr_p': 0.663, 'peak_level_Z': 3.29, 'cluster_level_FWEcorr_p': 0.998, 'set_level_p': '[]'}\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "# create a prov bundle to store the graph\n",
      "g = prov.ProvBundle()\n",
      "\n",
      "# define namespaces \n",
      "nidm_ns = prov.Namespace(\"nidm\", \"http://nidm.nidash.org/\")\n",
      "spm_ns = prov.Namespace(\"spm\", \"www.fil.ion.ucl.ac.uk/spm/\")\n",
      "neurolex_ns = prov.Namespace(\"neurolex\", \"http://neurolex.org/wiki/Main_Page/\")\n",
      "prov_ns = prov.Namespace(\"prov\", \"http://www.w3.org/ns/prov#\")\n",
      "\n",
      "# add namespaces to the graph\n",
      "g.add_namespace(nidm_ns)\n",
      "g.add_namespace(spm_ns)\n",
      "g.add_namespace(prov_ns)\n",
      "\n",
      "                \n",
      "\n",
      "# Height Threshold\n",
      "# create entity\n",
      "height_threshold_param_id=[0]*2\n",
      "height_threshold_param_id[0]=g.entity(\"height_threshold_param1\", [(prov.PROV[\"type\"],spm_ns[\"height_threshold\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"t-statistic\"]),\n",
      "                         (prov.PROV[\"label\"],\"Height Threshold\"),\n",
      "                         (prov.PROV[\"value\"],spm_metadata['hthresh_t'])]).get_identifier()\n",
      "height_threshold_param_id[1]=g.entity(\"height_threshold_param2\", [(prov.PROV[\"type\"],spm_ns[\"height_threshold\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"p-value\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"uncorrected_statistic\"]),\n",
      "                         (prov.PROV[\"label\"],\"Height_Threshold\"),\n",
      "                         (prov.PROV[\"value\"],spm_metadata['hthresh_p'])]).get_identifier()\n",
      "\n",
      "# create a height threshold collection\n",
      "height_threshold_collection_id=g.collection(\"height_threshold_collection\",[(prov.PROV['type'],spm_ns['Height_Threshold'])]).get_identifier()\n",
      "g.hadMember(height_threshold_collection_id,height_threshold_param_id[0])\n",
      "g.hadMember(height_threshold_collection_id,height_threshold_param_id[1])\n",
      "\n",
      "# Extent Threshold\n",
      "# create entity\n",
      "extent_threshold_param_id=[0]*2\n",
      "extent_threshold_param_id[0]=g.entity(\"extent_threshold_param1\", [(prov.PROV[\"type\"],spm_ns[\"extent_threshold\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"threhold\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"voxel\"]),\n",
      "                         (prov.PROV[\"label\"],\"Extent Threshold\"),\n",
      "                         (prov.PROV[\"value\"],spm_metadata['ext_thresh_vx'])]).get_identifier()\n",
      "extent_threshold_param_id[1]=g.entity(\"extent_threshold_param2\", [(prov.PROV[\"type\"],spm_ns[\"extent_threshold\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"p-value\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"uncorrected_statistic\"]),\n",
      "                         (prov.PROV[\"label\"],\"Extent_Threshold\"),\n",
      "                         (prov.PROV[\"value\"],spm_metadata['ext_thresh_p'])]).get_identifier()\n",
      "\n",
      "# create a extent threshold collection\n",
      "extent_threshold_collection_id=g.collection(\"extent_threshold_collection\",[(prov.PROV['type'],spm_ns['Extent_Threshold'])]).get_identifier()\n",
      "g.hadMember(extent_threshold_collection_id,extent_threshold_param_id[0])\n",
      "g.hadMember(extent_threshold_collection_id, extent_threshold_param_id[1])\n",
      "\n",
      "\n",
      "\n",
      "# Expected voxels per cluster\n",
      "# create entity\n",
      "expected_voxels_id=g.entity(\"expected_voxels\", [(prov.PROV[\"type\"],spm_ns[\"expected_voxels\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"VolumeInVoxels\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"voxel\"]),\n",
      "                         (prov.PROV[\"label\"],\"Expected_voxels_per_cluster\"),\n",
      "                         (prov.PROV[\"value\"],spm_metadata['exp_vox_cluster'])]).get_identifier()\n",
      "\n",
      "\n",
      "\n",
      "# Expected clusters\n",
      "# create entity\n",
      "expected_clusters_id=g.entity(\"expected_clusters\", [(prov.PROV[\"type\"],spm_ns[\"expected_clusters\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"cluster\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"voxel\"]),\n",
      "                         (prov.PROV[\"label\"],\"Expected_number_of_clusters\"),\n",
      "                         (prov.PROV[\"value\"],spm_metadata['exp_num_clusters'])]).get_identifier()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "metadata_collection=g.collection(\"spm_results_metadata\", [(prov.PROV['type'],spm_ns['spm_results_metadata'])]).get_identifier()\n",
      "g.hadMember(metadata_collection,height_threshold_collection_id) \n",
      "g.hadMember(metadata_collection,extent_threshold_collection_id)\n",
      "g.hadMember(metadata_collection,expected_voxels_id)\n",
      "g.hadMember(metadata_collection,expected_clusters_id)\n",
      "\n",
      "\n",
      "print g.get_provn()\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "document\n",
        "  prefix neurolex <http://neurolex.org/wiki/Main_Page/>\n",
        "  prefix spm <www.fil.ion.ucl.ac.uk/spm/>\n",
        "  prefix nidm <http://nidm.nidash.org/>\n",
        "  \n",
        "  entity(height_threshold_param1, [prov:type='spm:height_threshold', prov:type='neurolex:t-statistic', prov:label=\"Height Threshold\", prov:value=\"3.100000\" %% xsd:float])\n",
        "  entity(height_threshold_param2, [prov:type='spm:height_threshold', prov:type='neurolex:p-value', prov:type='neurolex:uncorrected_statistic', prov:label=\"Height_Threshold\", prov:value=\"0.001000\" %% xsd:float])\n",
        "  entity(height_threshold_collection, [prov:type='spm:Height_Threshold', prov:type='prov:Collection'])\n",
        "  hadMember(height_threshold_collection, height_threshold_param1)\n",
        "  hadMember(height_threshold_collection, height_threshold_param2)\n",
        "  entity(extent_threshold_param1, [prov:type='spm:extent_threshold', prov:type='neurolex:threhold', prov:type='neurolex:voxel', prov:label=\"Extent Threshold\", prov:value=0])\n",
        "  entity(extent_threshold_param2, [prov:type='spm:extent_threshold', prov:type='neurolex:p-value', prov:type='neurolex:uncorrected_statistic', prov:label=\"Extent_Threshold\", prov:value=\"1.000000\" %% xsd:float])\n",
        "  entity(extent_threshold_collection, [prov:type='spm:Extent_Threshold', prov:type='prov:Collection'])\n",
        "  hadMember(extent_threshold_collection, extent_threshold_param1)\n",
        "  hadMember(extent_threshold_collection, extent_threshold_param2)\n",
        "  entity(expected_voxels, [prov:type='spm:expected_voxels', prov:type='neurolex:VolumeInVoxels', prov:type='neurolex:voxel', prov:label=\"Expected_voxels_per_cluster\", prov:value=\"60.632000\" %% xsd:float])\n",
        "  entity(expected_clusters, [prov:type='spm:expected_clusters', prov:type='neurolex:cluster', prov:type='neurolex:voxel', prov:label=\"Expected_number_of_clusters\", prov:value=\"9.510000\" %% xsd:float])\n",
        "  entity(spm_results_metadata, [prov:type='spm:spm_results_metadata', prov:type='prov:Collection'])\n",
        "  hadMember(spm_results_metadata, height_threshold_collection)\n",
        "  hadMember(spm_results_metadata, extent_threshold_collection)\n",
        "  hadMember(spm_results_metadata, expected_voxels)\n",
        "  hadMember(spm_results_metadata, expected_clusters)\n",
        "endDocument\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#SPM table\n",
      "\n",
      "#set-level stats\n",
      "# create entity\n",
      "set_level_id=[0]*2\n",
      "set_level_id[0]=g.entity(\"set_level_p\", [(prov.PROV[\"type\"],spm_ns[\"set-level\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"p-value\"]),\n",
      "                         (prov.PROV[\"label\"],\"set_level_p\"),\n",
      "                         (prov.PROV[\"value\"],spm_results_table[1]['set_level_p'])]).get_identifier()\n",
      "set_level_id[1]=g.entity(\"set_level_c\", [(prov.PROV[\"type\"],spm_ns[\"set-level\"]),\n",
      "                         (prov.PROV[\"type\"],neurolex_ns[\"cluster\"]),\n",
      "                         (prov.PROV[\"label\"],\"set_level_c\"),\n",
      "                         (prov.PROV[\"value\"],spm_results_table[1]['set_level_c'])]).get_identifier()\n",
      "\n",
      "# create a extent threshold collection\n",
      "set_level_collection_id=g.collection(\"set_level_collection\",[(prov.PROV['type'],spm_ns['set-level'])]).get_identifier()\n",
      "g.hadMember(set_level_collection_id,set_level_id[0])\n",
      "g.hadMember(set_level_collection_id,set_level_id[1])\n",
      "\n",
      "#print g.get_provn()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<prov.model.ProvMembership at 0x195cf70>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#SPM table\n",
      "\n",
      "#coordinate entities\n",
      "\n",
      "#query of spm_results_table for number of coordinates\n",
      "num_loc=set(dat for dat in spm_results_table if spm_results_table[dat]['loc'])\n",
      "\n",
      "#declare coordinate id array\n",
      "coords_id = [0]*len(num_loc)\n",
      "\n",
      "#create a coordinate collection\n",
      "coords_collection_id=g.collection(\"coordinates\",[(prov.PROV['type'],spm_ns['mm_mm_mm'])]).get_identifier()\n",
      "\n",
      "\n",
      "#for each coordinate, create an entity\n",
      "for i in num_loc:\n",
      "    coords_id[i] = g.entity(\"coord_\"+str(i), [(prov.PROV[\"type\"],neurolex_ns[\"coordinate\"]),\n",
      "                         (prov.PROV[\"type\"],nidm_ns[\"units\"]),\n",
      "                         (prov.PROV[\"label\"],\"mm_mm_mm\"),\n",
      "                         (prov.PROV[\"value\"],spm_results_table[i]['loc'])]).get_identifier()\n",
      "\n",
      "    g.hadMember(coords_collection_id,coords_id[i])\n",
      "\n",
      "print g.get_provn()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "document\n",
        "  prefix neurolex <http://neurolex.org/wiki/Main_Page/>\n",
        "  prefix spm <www.fil.ion.ucl.ac.uk/spm/>\n",
        "  prefix nidm <http://nidm.nidash.org/>\n",
        "  \n",
        "  entity(height_threshold_param1, [prov:type='spm:height_threshold', prov:type='neurolex:t-statistic', prov:label=\"Height Threshold\", prov:value=\"3.100000\" %% xsd:float])\n",
        "  entity(height_threshold_param2, [prov:type='spm:height_threshold', prov:type='neurolex:p-value', prov:type='neurolex:uncorrected_statistic', prov:label=\"Height_Threshold\", prov:value=\"0.001000\" %% xsd:float])\n",
        "  entity(height_threshold_collection, [prov:type='spm:Height_Threshold', prov:type='prov:Collection'])\n",
        "  hadMember(height_threshold_collection, height_threshold_param1)\n",
        "  hadMember(height_threshold_collection, height_threshold_param2)\n",
        "  entity(extent_threshold_param1, [prov:type='spm:extent_threshold', prov:type='neurolex:threhold', prov:type='neurolex:voxel', prov:label=\"Extent Threshold\", prov:value=0])\n",
        "  entity(extent_threshold_param2, [prov:type='spm:extent_threshold', prov:type='neurolex:p-value', prov:type='neurolex:uncorrected_statistic', prov:label=\"Extent_Threshold\", prov:value=\"1.000000\" %% xsd:float])\n",
        "  entity(extent_threshold_collection, [prov:type='spm:Extent_Threshold', prov:type='prov:Collection'])\n",
        "  hadMember(extent_threshold_collection, extent_threshold_param1)\n",
        "  hadMember(extent_threshold_collection, extent_threshold_param2)\n",
        "  entity(expected_voxels, [prov:type='spm:expected_voxels', prov:type='neurolex:VolumeInVoxels', prov:type='neurolex:voxel', prov:label=\"Expected_voxels_per_cluster\", prov:value=\"60.632000\" %% xsd:float])\n",
        "  entity(expected_clusters, [prov:type='spm:expected_clusters', prov:type='neurolex:cluster', prov:type='neurolex:voxel', prov:label=\"Expected_number_of_clusters\", prov:value=\"9.510000\" %% xsd:float])\n",
        "  entity(spm_results_metadata, [prov:type='spm:spm_results_metadata', prov:type='prov:Collection'])\n",
        "  hadMember(spm_results_metadata, height_threshold_collection)\n",
        "  hadMember(spm_results_metadata, extent_threshold_collection)\n",
        "  hadMember(spm_results_metadata, expected_voxels)\n",
        "  hadMember(spm_results_metadata, expected_clusters)\n",
        "  entity(set_level_p, [prov:type='spm:set-level', prov:type='neurolex:p-value', prov:label=\"set_level_p\", prov:value=\"[]\"])\n",
        "  entity(set_level_c, [prov:type='spm:set-level', prov:type='neurolex:cluster', prov:label=\"set_level_c\", prov:value=\"[]\"])\n",
        "  entity(set_level_collection, [prov:type='spm:set-level', prov:type='prov:Collection'])\n",
        "  hadMember(set_level_collection, set_level_p)\n",
        "  hadMember(set_level_collection, set_level_c)\n",
        "  entity(coordinates, [prov:type='spm:mm_mm_mm', prov:type='prov:Collection'])\n",
        "  entity(coord_0, [prov:type='neurolex:coordinate', prov:type='nidm:units', prov:label=\"mm_mm_mm\", prov:value=\"[48, 42,0]\"])\n",
        "  hadMember(coordinates, coord_0)\n",
        "  entity(coord_1, [prov:type='neurolex:coordinate', prov:type='nidm:units', prov:label=\"mm_mm_mm\", prov:value=\"[54, 36,-12]\"])\n",
        "  hadMember(coordinates, coord_1)\n",
        "  entity(coord_2, [prov:type='neurolex:coordinate', prov:type='nidm:units', prov:label=\"mm_mm_mm\", prov:value=\"[-20, 52,32]\"])\n",
        "  hadMember(coordinates, coord_2)\n",
        "  entity(coord_3, [prov:type='neurolex:coordinate', prov:type='nidm:units', prov:label=\"mm_mm_mm\", prov:value=\"[54, 36,-12]\"])\n",
        "  hadMember(coordinates, coord_3)\n",
        "  entity(coord_4, [prov:type='neurolex:coordinate', prov:type='nidm:units', prov:label=\"mm_mm_mm\", prov:value=\"[38, 52,-30]\"])\n",
        "  hadMember(coordinates, coord_4)\n",
        "endDocument\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#SPM table\n",
      "\n",
      "#cluster-level stats\n",
      "\n",
      "\n",
      "#query of spm_results_table for number of cluster-level entries\n",
      "num_stats=set(dat for dat in spm_results_table if spm_results_table[dat]['cluster_level_FWEcorr_p'] != \"[]\")\n",
      "\n",
      "#declare cluster-level stats id array\n",
      "cluster_id = [0]*len(num_stats)*4\n",
      "\n",
      "#create a cluster-level stats collection\n",
      "cluster_collection_id=g.collection(\"cluster_level_stats\",[(prov.PROV['type'],spm_ns['cluster-level'])]).get_identifier()\n",
      "\n",
      "\n",
      "#for each cluster-level stat, create an entity\n",
      "for i in range(len(num_stats)):\n",
      "\n",
      "    \n",
      "    #for each attribute about the cluster stat, create an entity \n",
      "    indx=0\n",
      "    for j in spm_results_table[i]:\n",
      "            \n",
      "            #if we have a FWE p-value stat, create appropriate entity\n",
      "            if (re.search(r\"\\bcluster\\w+_FWEcorr_p\\b\",j, re.IGNORECASE)):\n",
      "                cluster_id[(i*len(num_stats))+indx] = g.entity(\"cluster_\"+str((i*len(num_stats))+indx), [(prov.PROV[\"type\"],neurolex_ns[\"p-value\"]),\n",
      "                             (prov.PROV[\"type\"],neurolex_ns[\"FWE\"]),\n",
      "                             (prov.PROV[\"label\"],j),\n",
      "                             (prov.PROV[\"value\"],spm_results_table[i][j])]).get_identifier()\n",
      "                g.hadMember(cluster_collection_id,cluster_id[(i*len(num_stats))+indx])\n",
      "                #now link to respective coordinate\n",
      "                \n",
      "                indx=indx+1\n",
      "    \n",
      "            #if we have an FDR p-value stat, create approriate entity\n",
      "            elif (re.search(r\"\\bcluster\\w+FDRcorr_p\\b\",j, re.IGNORECASE)):\n",
      "                cluster_id[(i*len(num_stats))+indx] = g.entity(\"cluster_\"+str((i*len(num_stats))+indx), [(prov.PROV[\"type\"],neurolex_ns[\"p-value\"]),\n",
      "                             (prov.PROV[\"type\"],neurolex_ns[\"FDR\"]),\n",
      "                             (prov.PROV[\"label\"],j),\n",
      "                             (prov.PROV[\"value\"],spm_results_table[i][j])]).get_identifier() \n",
      "                g.hadMember(cluster_collection_id,cluster_id[(i*len(num_stats))+indx])\n",
      "                indx=indx+1\n",
      "            \n",
      "            #if we have an Ke stat, create approriate entity\n",
      "            elif (re.search(r\"\\bcluster\\w+Ke\\b\",j, re.IGNORECASE)):\n",
      "                 cluster_id[(i*len(num_stats))+indx] = g.entity(\"cluster_\"+str((i*len(num_stats))+indx), [(prov.PROV[\"type\"],neurolex_ns[\"VolumeInVoxels\"]),\n",
      "                             (prov.PROV[\"type\"],neurolex_ns[\"cluster-level\"]),\n",
      "                             (prov.PROV[\"label\"],j),\n",
      "                             (prov.PROV[\"value\"],spm_results_table[i][j])]).get_identifier() \n",
      "                 g.hadMember(cluster_collection_id,cluster_id[(i*len(num_stats))+indx])\n",
      "                 indx=indx+1\n",
      "    \n",
      "            #if we have an uncorrected p-value stat, create approriate entity\n",
      "            elif (re.search(r\"\\bcluster\\w+Uncorr_p\\b\",j, re.IGNORECASE)):\n",
      "                 cluster_id[(i*len(num_stats))+indx] = g.entity(\"cluster_\"+str((i*len(num_stats))+indx), [(prov.PROV[\"type\"],neurolex_ns[\"p-value\"]),\n",
      "                             (prov.PROV[\"type\"],neurolex_ns[\"uncorrected_p-value\"]),\n",
      "                             (prov.PROV[\"label\"],j),\n",
      "                             (prov.PROV[\"value\"],spm_results_table[i][j])]).get_identifier() \n",
      "                 g.hadMember(cluster_collection_id,cluster_id[(i*len(num_stats))+indx])\n",
      "                 indx=indx+1\n",
      "\n",
      "#print g.get_provn()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#g.get_value??\n",
      "#g.get_value(g.coords_id[1])\n",
      "print g.get_attributes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "coord_0\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#SPM table\n",
      "\n",
      "#peak-level stats\n",
      "\n",
      "\n",
      "#query of spm_results_table for number of peak-level entries\n",
      "num_stats=set(dat for dat in spm_results_table if spm_results_table[dat]['peak_level_FWEcorr_p'] > 0)\n",
      "\n",
      "#declare peak-level stats id array\n",
      "peak_id = [0]*len(num_stats)*5\n",
      "\n",
      "#create a peak-level stats collection\n",
      "peak_collection_id=g.collection(\"peak_level_stats\",[(prov.PROV['type'],spm_ns['peak-level'])]).get_identifier()\n",
      "\n",
      "\n",
      "#for each peak-level stat, create an entity\n",
      "for i in range(len(num_stats)):\n",
      "\n",
      "    \n",
      "    #for each attribute about the peak stat, create an entity \n",
      "    indx=0\n",
      "    for j in spm_results_table[i]:\n",
      "            \n",
      "            #if we have a FWE p-value stat, create appropriate entity\n",
      "            if (re.search(r\"\\bpeak\\w+_FWEcorr_p\\b\",j, re.IGNORECASE)):\n",
      "                peak_id[(i*len(num_stats))+indx] = g.entity(\"peak_\"+str((i*len(num_stats))+indx), [(prov.PROV[\"type\"],neurolex_ns[\"p-value\"]),\n",
      "                             (prov.PROV[\"type\"],neurolex_ns[\"FWE\"]),\n",
      "                             (prov.PROV[\"label\"],j),\n",
      "                             (prov.PROV[\"value\"],spm_results_table[i][j])]).get_identifier()\n",
      "                g.hadMember(peak_collection_id,peak_id[(i*len(num_stats))+indx])\n",
      "                indx=indx+1\n",
      "    \n",
      "            #if we have an FDR p-value stat, create approriate entity\n",
      "            elif (re.search(r\"\\bpeak\\w+FDRcorr_p\\b\",j, re.IGNORECASE)):\n",
      "                peak_id[(i*len(num_stats))+indx] = g.entity(\"peak_\"+str((i*len(num_stats))+indx), [(prov.PROV[\"type\"],neurolex_ns[\"p-value\"]),\n",
      "                             (prov.PROV[\"type\"],neurolex_ns[\"FDR\"]),\n",
      "                             (prov.PROV[\"label\"],j),\n",
      "                             (prov.PROV[\"value\"],spm_results_table[i][j])]).get_identifier() \n",
      "                g.hadMember(peak_collection_id,peak_id[(i*len(num_stats))+indx])\n",
      "                indx=indx+1\n",
      "            \n",
      "            #if we have an T stat, create approriate entity\n",
      "            elif (re.search(r\"\\bpeak\\w+T\\b\",j, re.IGNORECASE)):\n",
      "                 peak_id[(i*len(num_stats))+indx] = g.entity(\"peak_\"+str((i*len(num_stats))+indx), [(prov.PROV[\"type\"],neurolex_ns[\"t-statistic\"]),\n",
      "                             (prov.PROV[\"type\"],neurolex_ns[\"peak-level\"]),\n",
      "                             (prov.PROV[\"label\"],j),\n",
      "                             (prov.PROV[\"value\"],spm_results_table[i][j])]).get_identifier() \n",
      "                 g.hadMember(peak_collection_id,peak_id[(i*len(num_stats))+indx])\n",
      "                 indx=indx+1\n",
      "            #if we have an Z stat, create approriate entity\n",
      "            elif (re.search(r\"\\bpeak\\w+Z\\b\",j, re.IGNORECASE)):\n",
      "                 peak_id[(i*len(num_stats))+indx] = g.entity(\"peak_\"+str((i*len(num_stats))+indx), [(prov.PROV[\"type\"],neurolex_ns[\"z-statistic\"]),\n",
      "                             (prov.PROV[\"type\"],neurolex_ns[\"peak-level\"]),\n",
      "                             (prov.PROV[\"label\"],j),\n",
      "                             (prov.PROV[\"value\"],spm_results_table[i][j])]).get_identifier() \n",
      "                 g.hadMember(peak_collection_id,peak_id[(i*len(num_stats))+indx])\n",
      "                 indx=indx+1\n",
      "    \n",
      "            #if we have an uncorrected p-value stat, create approriate entity\n",
      "            elif (re.search(r\"\\bpeak\\w+Uncorr_p\\b\",j, re.IGNORECASE)):\n",
      "                 peak_id[(i*len(num_stats))+indx] = g.entity(\"peak_\"+str((i*len(num_stats))+indx), [(prov.PROV[\"type\"],neurolex_ns[\"p-value\"]),\n",
      "                             (prov.PROV[\"type\"],neurolex_ns[\"uncorrected_p-value\"]),\n",
      "                             (prov.PROV[\"label\"],j),\n",
      "                             (prov.PROV[\"value\"],spm_results_table[i][j])]).get_identifier() \n",
      "                 g.hadMember(peak_collection_id,peak_id[(i*len(num_stats))+indx])\n",
      "                 indx=indx+1\n",
      "    \n",
      "#print g.get_provn()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spm_results = g.collection(\"spm_contrast_results\",[(prov.PROV['type'],spm_ns['spm_contrast_results'])]).get_identifier()\n",
      "g.hadMember(spm_results, peak_collection_id)\n",
      "g.hadMember(spm_results, cluster_collection_id)\n",
      "g.hadMember(spm_results, coords_collection_id)\n",
      "g.hadMember(spm_results, set_level_collection_id)\n",
      "g.hadMember(spm_results, metadata_collection)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'coordinate_collection_id' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-9-a845a94b4cfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhadMember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspm_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeak_collection_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhadMember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspm_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_collection_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhadMember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspm_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoordinate_collection_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhadMember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspm_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_level_collection_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhadMember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspm_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_collection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'coordinate_collection_id' is not defined"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"spm_results.provn\",'w') as f:\n",
      "    f.write(g.get_provn())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}